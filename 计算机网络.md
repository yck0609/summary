# 1 计算机网络

> 计算机网络指通过通信设备和通信介质连接的多台计算机系统，目的是实现数据的传输和通信，使得用户可以在不同的计算机之间发送和接收数据。通过计算机网络，用户可以进行远程访问、文件共享、电子邮件、网上聊天、视频会议等各种网络应用和服务

## 1.1 计算机网络组成

### 1.1.1 边缘部分和核心部分

> 边缘部分和核心部分共同构成了计算机网络的基本架构。边缘部分负责用户与网络之间的交互和数据处理，核心部分则负责数据的传输和路由选择

1. **边缘部分**：边缘部分是计算机网络中的<mark>用户端</mark>，是网络的最外层，与用户直接交互，通过网络连接与核心部分进行通信，提供数据的产生、处理、存储和传输等应用和服务

2. **核心部分**：核心部分是计算机网络中的<mark>传输部分</mark>，由大量的网络设备和链路组成，用于在边缘部分之间传输数据，实现数据的高效传输和路由选择，确保数据能够快速、可靠地从源节点传输到目标节点

### 1.1.2 通信子网和资源子网

> 通信子网负责数据的传输和通信，资源子网负责资源的共享和协同工作，两者共同构成计算机网络的基础设施，实现数据的传输、共享和交换

1. **通信子网**：计算机网络中<mark>负责数据传输和通信的部分</mark>，包括网络设备（如路由器、交换机、网桥等）和通信介质（如光纤、电缆、无线信道等），负责将数据从发送端传输到接收端，实现数据在网络中的传递和路由选择
2. **资源子网**：计算机网络中<mark>提供共享资源和服务的部分</mark>，包括网络中的计算机和服务器，用于提供应用程序、存储、处理和其他网络服务，提供了网络中的各种资源，如文件共享、打印服务、数据库访问等，以满足用户的需求

## 1.2 计算机网络分类

### 1.2.1 网络范围

1. **个人局域网（Personal Area Network，PAN）**：覆盖个人周围较小范围的计算机网络，使用无线技术（如蓝牙）或有线技术（如USB）连接个人设备，用于实现个人设备之间的数据传输和共享

2. **局域网（Local Area Network，LAN）**：覆盖较小范围的计算机网络，采用高速传输技术和低延迟的传输介质，用于连接局部区域内的计算机和设备

3. **城域网（Metropolitan Area Network，MAN）**：覆盖较大范围的计算机网络，由多个局域网互连而成，用于连接城市范围内的计算机和设备

4. **广域网（Wide Area Network，WAN）**：覆盖更大范围（通常跨越多个城市或国家）的计算机网络，使用公共的传输介质（如电话线、光纤）和传输技术（如电路交换、分组交换），用于连接远距离的计算机和设备

5. **互联网（Internet）**：全球范围内的计算机网络，由众多的局域网、城域网和广域网互连而成，使用TCP/IP协议族作为通信协议，提供全球范围内的信息交流和资源共享

### 1.2.2 网络拓扑结构

<img src="https://pic1.zhimg.com/v2-7815013b9b6381e1ee119bc948db75a8_r.jpg" title="" alt="" data-align="center">

1. **星型拓扑**：所有计算机和设备都连接到中央节点，中央节点负责转发数据包，协调网络通信，简单、易于管理，但中央节点成为了单点故障
2. **环型拓扑**：每个计算机和设备都与相邻设备直接连接，形成一个环形结构，数据通过环形路径传输，每个设备都可以接收和转发数据，具有高度可靠性和容错性，但扩展性较差
3. **总线型拓扑**：所有计算机和设备都连接到一个共享的传输介质（传输线或电缆），数据通过传输介质广播到所有连接的设备，简单、成本低，但传输介质的故障可能导致整个网络中断
4. **树型拓扑**：计算机和设备通过交换机或集线器连接成一个层次结构，允许网络分段和分级，便于管理和扩展，适用于大型网络，但依赖于中央节点的可靠性
5. **网状型拓扑**：每个计算机和设备都与其他设备直接连接，形成一个多对多的连接结构，具有高度可靠性和容错性，可以提供多条传输路径，但成本较高且复杂度较高

### 1.2.3 传输技术

1. **广播式传输技术**：数据从一个源节点发送到网络中的所有其他节点，数据通过网络中的广播机制，被所有其他节点接收和处理
2. **点对点传输技术**：数据通过直接的点对点连接从一个源节点发送到一个目标节点，源节点发送的数据只会被目标节点接收和处理，而不会被其他节点接收

### 1.2.4 交换技术

> 报文是在通信中传输的一段完整的数据，是通信的基本单位，可以包含文本、图像、音频或其他类型的信息。报文通常由两个主要部分组成：
> 
> 1. **报文头（Header）**：报文头包含与传输相关的控制信息，例如源地址、目标地址、数据长度、错误检测等，提供了必要的元数据，以确保正确的传输和处理
> 
> 2. **报文体（Body）**：报文体包含了实际的数据内容，可以是文本、图像、音频等任意形式的信息。报文体的格式和内容根据具体的应用和协议而定

1. **电路交换技术**：在通信建立时分配固定的专用的通信路径，数据会沿着这条路径进行传输。电路交换技术会占用固定的带宽资源，即使在通信双方不进行数据传输时也会保持占用状态
2. **报文交换技术**：数据按照报文进行传输，每个报文都包含完整的源地址和目的地址信息，通信双方通过交换报文进行通信。报文交换技术相对于电路交换技术更加灵活，因为通信路径不需要提前建立，而是根据报文中的地址信息进行动态路由
3. **分组交换技术**：将数据划分为小的数据包（分组）进行传输，每个数据包都包含源地址和目的地址信息，以及数据的一部分。在传输过程中，数据包可以通过不同的路径独立传输，并在目的地重新组合成完整的数据

### 1.2.5 传输介质

1. **有线传输介质**：如电缆、光纤等物理介质，用于通过电信号或光信号传输数据

2. **无线传输介质**：如无线信号，通过无线电波或红外线等传输数据

### 1.2.6 使用者

1. **公用网络**：公用网络是对所有用户开放的网络，任何人都可以使用公用网络进行通信和访问资源

2. **专用网络**：专用网络是为特定组织或个人所拥有和使用的网络，如企业内部网络或个人家庭网络，只有授权的用户才能使用专用网络

## 1.3 计算机网络性能指标

### 1.3.1 速率

> 速率描述数据传输的快慢程度，单位为比特率（bit rate，bits per second，b/s，bps）或者数据传输速率（data transfer rate，bytes per second，Bps），比特率指单位时间内传输的比特数，数据传输速率指单位时间内传输的数据量

#### 1.3.1.1 带宽（Bandwidth）

> 带宽描述网络链路或通信信道传输数据的能力或容量，速率的理论极值，指单位时间内通过网络链路或通信信道的最大数据量，单位为比特率或数据传输速率

#### 1.3.1.2 吞吐量（Throughput）

> 吞吐量指网络在单位时间内实际传输的数据量，表示网络链路或通信信道实际传输数据的速率，单位为比特率或数据传输速率

### 1.3.2 时延（Latency）

1. **发送时延（Transmission Delay）**：发送时延是指数据从发送方开始发送到发送完毕所需的时间。它由数据的长度和发送速率决定
   
   $$
   发送时延 = \frac{数据长度}{发送速率}
   $$

2. **传播时延（Propagation Delay）**：传播时延指数据从发送端传播到接收端所需的时间，取决于信号在传输介质中的传播速度和传输距离
   
   $$
   \text{传播时延} = \frac{\text{传输距离}}{\text{传播速度}}
   $$

3. **处理时延（Processing Delay）**：处理时延是指数据在网络设备（如路由器）上进行处理所需的时间，包括路由选择、数据包转发等操作

4. **排队时延（Queuing Delay）**：排队时延是指数据在网络设备的输入队列中等待处理所需的时间，当网络设备的处理能力有限或输入流量过大时，数据包可能需要在队列中等待

### 1.3.3 时延带宽积（Delay-Bandwidth Product）

> 时延带宽积描述在网络链路上存储的未传输数据量，单位是比特（bits）或字节（bytes）

$$
\text{时延带宽积} = \text{传播时延} \times \text{链路带宽}
$$

### 1.3.4 往返时间（Round-Trip Time，RTT）

RTT是衡量从发送方发送数据到接收方并接收到确认（ACK）所需的时间。RTT包括了数据传输时间、传播时延以及处理时延等因素。它是往返的时间，即从发送方到接收方再返回发送方的总时间。RTT可以通过以下步骤计算：

1. 发送方发送数据包到接收方。

2. 接收方接收到数据包后，发送确认（ACK）回发送方。

3. 发送方接收到确认后，计算发送数据到接收确认的时间差。

### 1.3.5 利用率（Utilization）

利用率指网络资源在一定时间内被使用的比例或程度，用于衡量网络的效率和性能。基于网络的排队模型符合独立同态（independent and homogeneous）的假设，网络的时延与利用率之间存在线性关系，令$D_0$ 表示网络空闲时的时延，即当网络没有任何传输时的基本延迟。$D$ 表示当前网络的时延，即在实际使用中观察到的延迟。$U$ 表示网络的利用率，即网络资源被使用的比例，有

$$
D = \frac{D_0}{1 - U}
$$

### 1.3.6 丢包率（Packet Loss Rate）

丢包率是指在数据传输过程中丢失的数据包的比例

$$
\text{丢包率} = \frac{\text{丢失的数据包数量}}{\text{发送的数据包数量}} \times 100\%
$$

其中，丢失的数据包数量是指在数据传输过程中未能到达目的地的数据包数量，发送的数据包数量是指在同一时间段内发送的数据包总数

## 1.4 计算机网络工作方式

### 1.4.1 点对点（Point-to-Point）

> 点对点网络<mark>直接连接两个节点</mark>，节点之间建立一条直接的通信链路，可以进行点对点的数据传输，适用于需要直接通信的场景，如电话线路、点对点连接的局域网等

### 1.4.2 广播（Broadcast）

> 广播网络将数据包从<mark>一个节点发送到所有其他节点</mark>。在广播网络中，发送节点将数据包广播到整个网络，所有其他节点都能接收到这个数据包。这种工作方式适用于需要向所有节点发送相同信息的场景，如广播电视、无线局域网中的广播消息等

### 1.4.3 多点通信（Multicast）

> 多点通信网络将数据包<mark>从一个节点发送到一组特定节点</mark>，只有属于该组的节点才能接收到该数据包，适用于向特定组进行通信的场景，如视频会议、流媒体传输等

### 1.4.4 客户端-服务器（Client-Server）

> 客户端-服务器网络基于请求和响应，有一个或多个服务器提供服务，而客户端向服务器发送请求并接收响应。服务器负责处理客户端的请求并提供相应的服务，适用于需要提供服务和资源的场景，如Web服务器、电子邮件服务器等

### 1.4.5 对等（Peer-to-Peer）

> 对等网络是一种分布式的网络模式，其中所有节点都可以充当客户端和服务器，节点之间可以直接通信，并共享资源和服务，而不依赖于中心化的服务器，适用于需要分布式共享和协作的场景，如文件共享、点对点通信等

## 1.5 计算机网络体系结构

> 计算机网络体系结构指计算机网络分为多层次，每个层次定义相应功能和协议集合，负责特定功能。计算机网络体系结构为计算机网络提供规范框架，更好地理解和设计计算机网络，确保网络的稳定性、可靠性和可扩展性，使得不同的设备和系统能够在网络中进行通信和交互

![](https://pic3.zhimg.com/v2-58b9b8ba7c2e733b33578a645164f1ca_b.jpg)

### 1.5.1 实体（entity）

> 实体指网络中的各种设备、主机或者节点，表示任何可发送或接收信息的硬件或软件进程，可以是计算机、路由器、交换机、服务器等物理设备或者虚拟设备

### 1.5.2 网络协议(network protocol)

> 网络协议是用于网络数据交换的规则、标准或约定，定义了在网络中的通信方式、数据格式、错误检测纠正、数据传输控制流程等细节，确保网络中的不同实体能够正确地进行通信，确保数据的可靠传输和正确解释

#### 1.5.2.1 网络协议要素

> 1. 语法：语法定义了数据和控制信息在网络中的结构或格式，规定数据包的组织方式、字段的含义和位置等。通过遵循协议的语法规则，发送方和接收方能够正确地解析和处理数据
> 
> 2. 语义：语义定义控制信息的含义，指明了在特定情况下应该发出何种控制信息、完成何种动作以及做出何种响应，规定了网络中各个实体之间的行为和交互方式，确保了网络的正常运行和数据的正确传输
> 
> 3. 同步：指明了事件实现的顺序和时序要求，详细说明了在数据交换和通信过程中各个步骤的顺序和时机，确保数据的有序传输和正确处理，使得网络中的各个实体能够按照规定的顺序进行操作，避免了数据混乱和通信错误

#### 1.5.2.2 网络协议的功能

> 1. 数据传输和路由：协议定义了数据在网络中的传输方式和路径选择，包括数据包的封装、分割、传输顺序等
> 
> 2. 错误检测和纠正：协议提供了机制来检测和纠正数据传输过程中的错误，如校验和、重传机制等
> 
> 3. 数据格式和编码：协议规定了数据的格式和编码方式，以确保不同设备和系统能够正确解释和处理数据
> 
> 4. 连接管理和控制：协议定义了建立、维护和关闭网络连接的过程，包括连接的建立、断开、流量控制等
> 
> 5. 安全和身份验证：协议提供了安全机制，如加密、身份验证等，以保护数据的机密性和完整性

### 1.5.3 服务

> 服务是指网络中提供给用户或其他实体的功能或资源，可以是网络应用程序、文件共享、电子邮件等，它们通过网络提供给用户使用。服务可以由一个或多个实体提供，并通过协议进行通信

### 1.5.4 服务访问点（Service Access Point，SAP）

> 在同一系统中相邻两层的实体进行交互（即交换信息）的地方，通常称为服务访问点。服务访问点是一个抽象的概念，它实际上就是一个逻辑接口，有点像邮政信箱（可以把邮件放入估箱和从信箱中取走邮件），但这种层间接口和内个设备之间的硬件接口（并行的或串钉的）并不一样。OSI 把层与厌之间交换的数据的单位称为服务数据单元SDU (Service Data Un it),它可以与PDU 不一样。例如，可以是多个SDU合成为一个PDU, 也可以是一个SDU 划分为几个PDU 服务访问点是指用户或其他实体与网络中的服务进行交互的接口或入口。服务访问点可以是一个URL、IP地址、域名等，用户可以通过这些访问点来请求和使用网络中的服务。服务访问点提供了访问服务所需的地址和协议信息

### 1.5.5 OSI 模型（Open Systems Interconnection）

> OSI参考模型是国际标准化组织（ISO）制定的一种计算机网络体系结构。它将计算机网络分为七个层次，每个层次负责不同的功能，每个层次都有特定的功能和协议集合，通过协议栈的方式实现数据的传输和通信

OSl 参考模型把对等层次之间传送的数据单位称为该层的协议数据单元PDU (Protocol
Data Unit)。这个名词现已被许多非OSI 标准采用。

![](https://haicoder.net/uploads/pic/network-protocol/http/http-hierarchical-model/07_OSI%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B%E5%9B%BE%E8%A7%A3.png)

### 1.5.6 TCP/IP 模型

> TCP/IP参考模型将计算机网络分为四个层次，每个层次负责不同的功能。这些层次从下至上分别是网络接口层（网络访问层）、网络层、传输层和应用层，是基于实际的互联网协议栈进行定义的，它是互联网通信的基础

![](https://img-blog.csdnimg.cn/20200228112021130.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NjM1MTU3,size_16,color_FFFFFF,t_70)

![](https://cache.yisu.com/upload/information/20201211/191/45953.jpg)

# 2 物理层

> 物理层位于网络协议栈的最底层，负责处理数据在物理媒介上的传输和接收，将比特流转换为适合在传输介质上传输的信号，确保数据能够在发送和接收设备之间可靠传输

## 2.1 数据通信系统模型

### 2.1.1 源系统

> 源系统是数据通信的起点，也称为发送端或发送方，负责生成、组织和发送数据，可以是计算机、服务器、传感器或其他设备

### 2.1.2 传输系统

> 传输系统是数据在网络中传输的媒介，由一系列网络设备、链路和协议组成，用于在源系统和目的系统之间传递数据，确保数据的可靠传输和交付

### 2.1.3 目的系统

> 目的系统是数据通信的终点，也称为接收端或接收方，负责接收、解析和处理从传输系统传输过来的数据，可以是计算机、服务器、终端设备或其他接收数据的设备

## 2.2 信道

> 信道是指在通信系统中用于传输信息的媒介或路径，承载着发送方传输的信号，并将其传递给接收方。信道可以是物理媒介，如电缆、光纤或无线电频谱，也可以是逻辑上定义的传输路径

### 2.2.1 单工通信

> 单工通信只允许信息在一个方向上进行传输，发送方将信息发送给接收方，但接收方无法回复，只需要一条信道即可实现

### 2.2.2 半双工通信

> 半双工通信允许通信双方发送信息，但不能同时发送和接收，通信的双方轮流发送和接收信息，双向交替通信需要两条信道，每个方向各一条

### 2.2.3 全双工通信

> 全双工通信允许通信双方同时发送和接收信息，通信的双方可以同时进行发送和接收操作，无需等待，实现即时交互，需要两条独立的信道，一条用于发送，另一条用于接收

## 2.3 信道的极限容量（Channel Capacity）

> 信道的极限容量是指在给定信道条件下的信息极限传输速率，受信道能够通过的频率范围与信噪比影响

### 2.3.1 码间串扰（Inter-Symbol Interference，ISI）

> 码间串扰是数字通信系统中的一种干扰现象，当信号经过信道传输时，信道的频率响应可能会导致相邻符号之间的能量相互干扰，使接收端在恢复发送的符号时产生误差，降低系统的性能

### 2.3.2 信噪比（Signal-to-Noise Ratio，SNR）

> 信噪比是信号与噪声之间相对强度的比值，单位为分贝（dB），信噪比越大信号质量越好。$P_{\text{signal}}$ 代表信号功率，$P_{\text{noise}}$ 代表噪声功率

$$
SNR(dB) = 10 \times \log_{10}\left(\frac{P_{signal}}{P_{noise}}\right)
$$

### 2.3.3 奈氏准则（Nyquist Criterion）

> 奈氏准则用于判断理想低通信道（无噪声干扰）中的信息极限传输速率，其带宽为B Hz，信息的极限传输速率为2B

$$
最大传输速率 = 2B
$$

### 2.3.4 香农公式（Shannon Formula）

> 香农公式描述在存在噪声的信道中信息的极限传输速率与信道带宽和信噪比成正比。B 代表信道的带宽（以赫兹为单位），SNR代表信噪比，最大传输速率 $C$（以比特每秒为单位）为

$$
C = B \log_2(1 + \text{SNR})
$$

## 2.4 信道复用

> 信道复用技术是一种在有限的通信资源（如频谱、时间等）上实现多用户或多信号传输的技术，允许多个信号共享同一通信介质，从而提高通信资源的利用率
> 
> 1. **频分复用（Frequency Division Multiplexing，FDM）**：不同用户或信号被分配到不同的频率带宽上进行传输，常用于广播电视和无线通信系统中，如多个电视频道共享同一传输介质
> 
> 2. **时分复用（Time Division Multiplexing，TDM）**：将时间分割成若干个时隙，不同用户或信号在不同的时隙上进行传输，常用于数字通信系统中，如电话网络中多个用户共享同一物理传输介质
> 
> 3. **码分复用（Code Division Multiplexing，CDM）**：使用不同的编码序列来区分不同用户或信号，允许它们在相同的频率和时间上进行传输，常用于无线通信系统中，如3G和4G移动通信系统
> 
> 4. **波分复用（Wavelength Division Multiplexing，WDM）**：将不同信号通过不同波长的光信号进行传输，常用于光纤通信系统中，以实现高容量的光通信

## 2.5 编码与调制

### 2.5.1 基带信号（Baseband Signal）

> 基带信号是指未经调制的原始信号，通常是模拟信号或数字信号，用于表示声音、图像、视频或其他类型的数据，其频率范围从直流到某个有限的最高频率，通常是低频信号或基频信号，适合直接处理和传输

### 2.5.2 频带信号（Passband Signal）

> 频带信号是指经过调制后的信号，其频率范围被移动到一个较高的频带

### 2.5.3 编码（Encoding）

> 编码是将数字信号转换为另一种形式（数字编码 / 模拟编码）的过程，以便在传输或存储中使用。常见的数字编码包括脉冲编码调制（PCM）、非归零编码（NRZ）、曼彻斯特编码等。模拟编码则是将数字信号转换为模拟信号的过程，常见的模拟编码包括脉冲振幅调制（PAM）和正交振幅调制（QAM）等

### 2.5.4 调制（Modulation）

> 调制是将基带信号转换为适合传输的信号形式（模拟信号 / 数字信号），以便在通信系统中传输和处理数据

#### 2.5.4.1 基带调制（Baseband Modulation）

> 基带调制是指将基带信号直接调制到通信系统的工作频率范围内，无需使用载波信号，常用于短距离通信系统，常见的基带调制方法包括脉冲编码调制（PCM）和基带振幅调制（Baseband Amplitude Modulation）等

#### 2.5.4.2 带通调制（Bandpass Modulation）/ 载波调制（Carrier Modulation）

> 带通调制是指将基带信号调制到一个特定频率范围内的载波信号上，以便在通信系统中传输和处理数据。带通调制常用于无线通信和广播系统中，通过将基带信号的特征嵌入到载波信号中，实现信息的传输和接收。常见的带通调制方法包括调幅（AM）、调频（FM）和调相（PM）等

## 2.6 常用编码方式

![](https://img-blog.csdnimg.cn/img_convert/5eab184265c07164e48770ec14975681.png)

### 2.6.1 非归零编码（Non-Return-to-Zero，NRZ）

> 通常使用高电平表示逻辑1，低电平表示逻辑0，简单直观，但可能会导致时钟同步问题和直流偏移问题

### 2.6.2 归零编码（Return-to-Zero，RZ）

> 归零编码解决了非归零编码的直流偏移问题。信号在每个位周期的前半段用高电平表示逻辑1，低电平表示逻辑0，而中间都返回到零电平，确保每个位周期都有一个过渡，从而提供了时钟同步的机会

### 2.6.3 曼彻斯特编码（Manchester Encoding）

> 曼彻斯特编码是一种自同步的数字信号编码方式，通过在每个位周期的中间引入电平变化来表示数据位，高电平到低电平表示逻辑1，低电平到高电平表示逻辑0，提供了时钟同步和数据恢复的机制，但需要较高的带宽

### 2.6.4 差分曼彻斯特编码（Differential Manchester Encoding）

> 差分曼彻斯特编码是曼彻斯特编码的一种变体，在信号位开始时不改变信号极性，表示逻辑1，在信号位开始时改变信号极性，表示逻辑0，在码元正中间时刻进行电平转换

## 2.6 基本的带通调制方法

![](https://howling.gitee.io/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/2043786-20210222112508539-1890703213.png)

### 2.6.1 调幅（Amplitude Modulation, AM）

> 调幅在载波信号的振幅上叠加信息信号，载波信号的振幅会随着信息信号的变化而变化。$s(t)$ 是调幅信号，$A_c$ 是载波的振幅，$k_a$ 是调幅系数，$m(t)$ 是信息信号，$f_c$ 是载波的频率

$$
s(t) = A_c \cdot [1 + k_a \cdot m(t)] \cdot \cos(2\pi f_c t)
$$

### 2.6.2 调频（Frequency Modulation, FM）

> 调频通过改变载波信号的频率来传输信息信号，信息信号的变化导致了载波频率的变化。$s(t)$ 是调频信号，$A_c$ 是载波的振幅，$f_c$ 是载波的频率，$k_f$ 是调频灵敏度，$m(t)$ 是信息信号

$$
s(t) = A_c \cdot \cos[2\pi f_c t + 2\pi k_f \int_0^t m(\tau) d\tau]
$$

### 2.6.3 调相（Phase Modulation, PM）

> 调相通过改变载波信号的相位来传输信息信号，信息信号的变化会导致载波相位的变化。$s(t)$ 是调相信号，$A_c$ 是载波的振幅，$f_c$ 是载波的频率，$k_p$ 是调相系数，$m(t)$ 是信息信号

$$
s(t) = A_c \cdot \cos[2\pi f_c t + k_p \cdot m(t)]
$$

# 3 数据链路层

> 数据链路层，位于物理层之上，网络层之下，负责将物理层提供的原始比特流转换为逻辑上的数据帧，并提供了一些基本的数据传输服务，通常在直接相连的两个节点之间进行通信

1. **封装成帧**：将网络层的数据包封装成数据帧，添加帧头和帧尾等必要信息，以便在链路上传输。每一种链路层协议都规定了所能传送的帧的数据部分长度上限即最大传送单元(Maximum Transfer Unit，MTU)

![](https://pic2.zhimg.com/v2-f3f315ecf9656b561e5e94d58cab4a2d_r.jpg)

1. **透明传输**：确保数据在链路上传输时对上层协议是透明的，即数据链路层的具体实现对上层协议是透明的，上层协议不需要关心数据链路层的具体细节

2. **错误检测与纠正**：通过校验和或其他方法检测传输过程中的错误，并在可能的情况下进行纠正

3. **链路接入**：管理共享介质的访问，处理多个设备共享同一物理链路时的冲突和协调问题

4. **流量控制**：协调发送方和接收方之间的数据传输速率，防止接收方被发送方淹没

5. **地址识别**：识别物理网络中的设备，并确定数据帧的目的地

## 3.1 基本概念

### 3.1.1 链路（link）

> 链路是指就是从一个节点到相邻节点的一段物理线路（有线 / 无线），中间没有任何其他的交换节点

### 3.1.2 数据链路（data link）

> 数据链路即链路加上一些必要的通信协议控制链路中的数据传输

### 3.1.3 帧（Frame）

> 帧是数据链路层中的基本传输单位，是数据链路层中点对点信道的协议数据单元，数据链路层把网络层发送的数据构成帧发送到链路上，把接收到的帧中的数据取出并上交给网络层

![](https://pic2.zhimg.com/v2-0231ecbf02f693813f05791bb85a094d_r.jpg)

1. **帧起始标志 (Start of Header，SOH)** ： 表示帧头的起始位置，用于指示数据帧的开始

2. **目的地址 (Destination Address)** : 指示接收帧的目标设备的地址

3. **源地址 (Source Address)** : 指示发送帧的源设备的地址

4. **类型/长度字段 (Type/Length Field)** : 指示帧中数据的类型或长度

5. **数据字段 (Data Field)**: 包含要传输的数据

6. **帧校验序列 (Frame Check Sequence, FCS)**: 用于检测帧在传输过程中是否发生了错误

7. **帧结束标志(End of Transmission，EOT)** : 用于标识帧的结束

8. **转义字符 (Escape，ESC)** : 用于转义其他特殊字符或控制字符，实现透明传输

### 3.1.4 MAC地址（Media Access Control address）

> MAC地址在数据链路层使用，用于在局域网中唯一标识网络设备，以便进行数据帧的定位和传输，由48位二进制数组成，通常以十六进制表示，如00:1A:2B:3C:4D:5E。MAC地址由厂商设定，唯一标识网络设备的网卡。前三个字节是厂商识别码，由IEEE注册管理，后三个字节由厂商自行分配

## 3.2 差错检测常用方法

### 3.2.1 循环冗余检验（Cyclic Redundancy Check，CRC）

> CRC是一种基于多项式除法的差错检测方法。发送方使用生成多项式对数据进行计算，并将计算结果附加到数据中发送给接收方。接收方使用相同的生成多项式对接收到的数据进行计算，然后与接收到的校验值进行比较，以检测是否存在差错

![](https://pic3.zhimg.com/80/v2-260a646896c579d8fd87b36be5729afa_720w.webp)

![](https://pic3.zhimg.com/80/v2-5d30171ce3d65f5ca1f4cfb35b95eb26_720w.webp)

![](https://pic4.zhimg.com/80/v2-2d02900d913b469d5f941615ba66c537_720w.webp)

### 3.2.2 海明码（Hamming Code）

> 海明码是一种常见的差错检测和纠正方法。海明码通过在数据中添加冗余位来实现差错检测和纠正。发送方使用特定的编码规则对数据进行编码，并在数据中添加冗余位。接收方在接收到数据后，使用海明码的纠错算法检测和纠正可能存在的差错

### 3.2.3 奇偶校验码（Parity Check）

> 奇偶校验码是一种简单的差错检测方法。在奇偶校验码中，发送方在每个数据块的末尾添加一个附加位，使得整个数据块中1的个数（或0的个数）为奇数（或偶数）。接收方在接收到数据后，计算接收到的数据块中1的个数（或0的个数），如果结果与附加位指示的奇偶性不一致，则发生了差错

### 3.2.4 水平奇偶校验（Horizontal Parity Check）

> 水平奇偶校验是一种应用于磁盘存储系统中的差错检测方法。在水平奇偶校验中，数据被划分成多个水平条带，每个水平条带包含多个数据块。对于每个水平条带，额外的奇偶校验块被添加到该条带的末尾，用于存储该条带中所有数据块的奇偶校验信息。接收方在接收到数据后，可以通过比较奇偶校验块的值与数据块的奇偶性来检测差错

### 3.2.5 垂直奇偶校验（Vertical Parity Check）

> 垂直奇偶校验也是一种应用于磁盘存储系统中的差错检测方法。与水平奇偶校验不同的是，垂直奇偶校验将数据划分为多个垂直条带，每个垂直条带包含多个数据块。对于每个垂直条带，额外的奇偶校验块被添加到该条带的末尾，用于存储该条带中所有数据块的奇偶校验信息。接收方可以通过比较奇偶校验块的值与数据块的奇偶性来检测差错

### 3.2.6 二维奇偶校验（Two-Dimensional Parity Check）

> 二维奇偶校验是一种应用于存储系统或数据传输中的差错检测方法。在二维奇偶校验中，数据被组织成一个二维矩阵，并在每行和每列添加额外的奇偶校验位。接收方在接收到数据后，可以通过比较每行和每列的奇偶校验位与对应数据的奇偶性来检测差错

## 3.3 点对点协议（Point-to-Po int Protocol，PPP）

> PPP是一种常用的点对点通信协议，用于在两个网络节点之间建立可靠的数据链路层连接。它可以通过串行线路、电话线、光纤等物理介质进行通信。PPP提供了一种灵活的协议框架，支持多种网络层协议（如IP、IPv6等）的封装和传输。它还提供了身份验证、错误检测、链路状态监测等功能，以确保可靠的数据传输

## 3.4 ALOHA

> ALOHA是一种简单的无线网络协议，用于多个终端共享一个共享介质（如无线信道）的通信。ALOHA协议最早应用于夏威夷大学的无线网络实验中。它基于随机访问的思想，终端可以在任何时间发送数据，但可能会发生碰撞（多个终端同时发送数据导致冲突）。碰撞发生后，终端会等待一个随机的时间间隔后再次尝试发送。ALOHA协议有两个变种：纯ALOHA和时隙ALOHA。纯ALOHA允许终端在任意时间发送数据，而时隙ALOHA将时间划分为时隙，终端只能在时隙开始时发送数据

### 3.4.1 纯ALOHA协议

纯ALOHA协议的优点是简单且易于实现，但由于没有时间同步和冲突避免机制，它可能会导致较高的信道利用率和较高的冲突率，从而影响系统的吞吐量。纯ALOHA协议的工作原理如下：

1. **发送数据**：当终端设备有数据要发送时，它可以直接在信道上进行发送，而无需等待其他设备。

2. **冲突检测**：如果两个或多个设备同时发送数据，它们的信号会在信道上碰撞，导致数据损坏。终端设备会检测到冲突并等待一段随机时间后再次尝试发送。

3. **重传机制**：如果发送的数据帧未被成功接收，终端设备会在等待一段随机时间后进行重传。

### 3.4.2 时隙ALOHA协议

时隙ALOHA协议在纯ALOHA的基础上引入了时间分割，以减少冲突和提高信道利用率。时隙ALOHA协议通过引入时隙同步和时间分割，有效地减少了冲突率和提高了信道利用率。然而，它仍然存在冲突和重传的问题，可能导致一定的信道浪费。时隙ALOHA的工作原理如下：

1. **时间分割**：将时间分割为固定长度的时隙，使每个时隙对应一个数据帧的传输时间。

2. **时隙同步**：终端设备在每个时隙开始时进行同步，以确保在正确的时隙中发送数据。

3. **发送数据**：终端设备只能在时隙的开始时发送数据，避免了冲突的发生。

4. **冲突检测和重传机制**：如果多个设备在同一个时隙发送数据，会发生冲突。终端设备会检测到冲突，并在下一个时隙重新发送。

## 3.5 载波监听多路访问协议（Carrier Sense Multiple Access，CSMA）

> CSMA是一种多路访问协议，基于载波监听的思想实现多用户共享信道

### 3.5.1 非持续性CSMA（Non-Persistent CSMA）

> 非持续性CSMA是一种基于载波监听的随机接入协议，其工作原理如下：当终端设备有数据要发送时，它首先监听信道，如果信道空闲，设备立即发送数据；如果信道忙碌，设备会等待一个随机的延迟时间，然后再次监听信道，直到信道空闲。非持续性CSMA通过随机选择延迟时间来避免多个设备同时发送数据，从而降低碰撞的概率。然而，由于随机性，可能会导致较长的等待时间。

### 3.5.2 1-坚持CSMA（1-Persistent CSMA）

> 1-坚持CSMA是另一种CSMA变种，其工作原理如下：当终端设备有数据要发送时，它首先监听信道，如果信道空闲，设备立即发送数据；如果信道忙碌，设备会持续监听信道，直到信道空闲，然后立即发送数据。1-坚持CSMA的特点是设备会坚持在信道空闲时立即发送数据，而不会进行随机的延迟等待。这种方法可以减少冲突，但也可能导致更多的碰撞。

### 3.5.3 p-坚持CSMA（p-Persistent CSMA）

> p-坚持CSMA是CSMA协议的另一个变种，其工作原理如下：当终端设备有数据要发送时，它首先监听信道，如果信道空闲，设备以概率p发送数据；如果信道忙碌，设备会等待下一个时隙，并以概率p继续监听信道，直到信道空闲。p-坚持CSMA引入了概率p的概念，设备在信道空闲时以概率p发送数据，这样可以在一定程度上平衡冲突和传输效率。p-坚持CSMA适用于具有固定时隙的系统，如时分多址（TDMA）系统

### 3.5.4 CSMA/CD（Carrier Sense Multiple Access with Collision Detection）

CSMA/CD是一种用于以太网等有线网络中的多路访问协议。它扩展了CSMA协议，并添加了碰撞检测的功能。当终端发送数据时，如果检测到碰撞（即多个终端同时发送数据导致冲突），终端会立即停止发送，并发送一个干扰信号通知其他终端发生了碰撞。然后，终端会等待一个随机的时间间隔后再次尝试发送数据。CSMA/CD协议适用于共享介质的局域网，如以太网。它能够有效地避免冲突和数据碰撞，并提供了一种分布式的冲突解决机制。然而，随着网络规模的增大和传输速率的提高，CSMA/CD的效率会降低，并且在现代高速网络中很少使用。CSMA/CD协议主要用于以太网局域网中，其工作原理如下：

1. **载波监听**：当终端设备有数据要发送时，它会先监听信道上是否有其他设备正在发送数据。如果检测到载波（即信道被占用），设备会等待一段时间，直到信道空闲。

2. **冲突检测**：如果多个设备同时开始发送数据，它们的信号会在信道上碰撞，导致数据损坏。终端设备会继续发送数据，并同时监听信道上的信号，以检测是否发生冲突。

3. **冲突检测和中断**：如果终端设备检测到冲突，它会立即停止发送数据，并发送一个中断信号通知其他设备发生了冲突。

4. **退避和重传机制**：当发生冲突时，终端设备会等待一个随机的时间间隔，然后重新尝试发送数据。这个随机的时间间隔称为退避时间。设备会在每次重传时增加退避时间的指数倍，以减少冲突的概率。

### 3.5.5 CSMA/CA（Carrier Sense Multiple Access with Collision Avoidance）

CSMA/CA是一种用于无线网络中的多路访问协议，如Wi-Fi。与CSMA/CD不同，CSMA/CA采用了碰撞避免的策略。终端在发送数据之前，先发送一个RTS（请求发送）帧，通知其他终端它要发送数据。其他终端收到RTS后，会等待一段时间再发送CTS（清除发送）帧，表示它们不会发送数据。这样可以避免碰撞。然后，终端发送数据，并等待接收到的ACK（确认）帧来确认数据的传输。CSMA/CA协议在无线网络中具有重要的作用，它通过载波监听和RTS/CTS握手机制，有效地避免了冲突和隐藏节点问题。然而，由于无线信道的特性，CSMA/CA仍然可能存在碰撞和延迟问题

CSMA/CA协议主要用于无线局域网（WLAN）和其他无线通信系统中，其工作原理如下：

1. **载波监听**：终端设备在发送数据之前，先监听信道上是否有其他设备正在发送数据。如果信道被占用，设备会等待一段时间，直到信道空闲。

2. **RTS/CTS握手**：为了避免隐藏节点问题（即终端设备无法检测到其他设备的存在），CSMA/CA引入了RTS（请求发送）和CTS（清除发送）握手机制。发送数据的设备首先发送一个RTS帧给接收设备，接收设备在收到RTS后发送一个CTS帧进行确认。这样，其他设备在收到CTS帧后知道信道将被占用，从而避免冲突。

3. **退避和重传机制**：如果终端设备未收到CTS帧或收到了冲突的信号，它会等待一个随机的退避时间，然后重新尝试发送数据。

# 4 网络层

> 网络层负责在不同网络之间提供数据传输的路径选择和转发功能

1. **路径选择**：网络层负责确定数据包从源到目的地的最佳路径

2. **转发**：网络层负责将数据包沿着选定的路径进行转发

3. **跨网络通信**：网络层处理不同网络技术和协议之间的互联互通，使得数据可以在全球范围内进行传输

## 4.1 IP 地址（Internet Protocol Address）

> IP地址用于在计算机网络中唯一标识和定位设备的地址

### 4.1.1 IP 地址结构

> IP地址分为网络部分和主机部分。网络部分用于标识网络，主机部分用于标识特定的主机或设备。根据IP地址的类别，网络部分和主机部分的长度是固定的或可变的

<img title="" src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xODE5OTAxOS1lNzEwMjExZDMwZDg3MWQxLnBuZw?x-oss-process=image/format,png" alt="" data-align="center" width="584">

### 4.1.2 IPv4地址分类

![](https://www.biaodianfu.com/wp-content/uploads/2021/08/ip-class.png)

1. **A类地址**：A类地址是用于大型网络的地址范围。它的网络部分占用了8位（第一个字节），而主机部分占用了24位。A类地址的范围是1.0.0.0到126.0.0.0，其中1.0.0.0是保留地址，用于特殊用途。A类地址可以分配给大型组织或国家级网络，每个网络可以容纳最多16777214个主机

2. **B类地址**：B类地址用于中等规模的网络。它的网络部分占用了16位（前两个字节），而主机部分占用了16位。B类地址的范围是128.0.0.0到191.255.0.0，其中128.0.0.0和191.255.0.0是保留地址。B类地址可以分配给中等规模的组织或大型企业，每个网络可以容纳最多65534个主机

3. **C类地址**：C类地址用于小型网络。它的网络部分占用了24位（前三个字节），而主机部分占用了8位。C类地址的范围是192.0.0.0到223.255.255.0，其中192.0.0.0和223.255.255.0是保留地址。C类地址可以分配给小型组织或中小型企业，每个网络可以容纳最多254个主机

4. **D类地址**：D类地址用于多播（Multicast）通信。它的地址范围是224.0.0.0到239.255.255.255。D类地址用于将数据包同时发送给一组特定的设备，而不是单个设备

5. **E类地址**：E类地址是保留地址，用于特殊用途。它的地址范围是240.0.0.0到255.255.255.255

### 4.1.3 IPv6地址分类

## 无分类域间路由选择（Classless Inter-Doma in Routing，CIDR）

# 5 传输层

运输层的任务就是负责向两台主机中进程之间的通信提供通用的数据传输服务。应用
进程利用该服务传送应用层报文。所谓“通用的“，是指并不针对某个特定网络应用，而是
多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个进程，因此运输层有复
用和分用的功能。复用就是多个应用层进程可同时使用下面运输层的服务，分用和复用相反，
是运输层把收到的信息分别交付上而应用层中的相应进程。
运输层主要使用以下两种协议：
• 传输控制协议TCP (Transmission Control Protocol}-—才是供面向连接的、可靠的数
据传输服务，其数据传输的单位是报文段(segmen t)。
• 用户数据报协议UDP (User Datagram Protocol)--提供无连接的尽最大努力(beste
ffort)的数据传输服务（不保证数据传输的可靠性），其数据传输的单位是用户数
据报。
顺便指出，有人愿意把运输层称为传输层，理由是这一层使用的TCP 协议就叫作传输
控制协议。从意思上看，传输和运输差别也不大。但OSI 定义的第4 层使用的是Transport,
而不是Transmission 。这两个词的含义还是有些差别的。因此，使用运输层这个译名较为准确。

# 6 应用层

应用层是体系结构中的最高层。应用层的任务是通过应用进程间的交互来完成特定网
络应用。应用层协议定义的是应用进程间通信和交互的规则。这里的进程就是指上机中正在
运行的程序。对千不同的网络应用斋要有不同的应用层协议。互联网中的应用层协议很多，
如域名系统ONS 、支持万维网应用的HTTP 协议、支待电子邮件的SMTP 协议，等等。找
们把应用层交互的数据单元称为报文(message) 。

应用层的协议哪些是基于 TCP 协议的，哪些是基于 UDP 协议的

### 基于 TCP 协议的

- FTP（文件传输协议）：定义了文件传输协议，使用 21 端口。
- TELNET（远程登陆协议）：一种用于远程登陆的端口，使用 23 端口，用户可以以自己的身份远程连接到计算机上，可提供基于 DOS 模式下的通信服务。
- SMTP（简单邮件传输协议）：邮件传送协议，用于发送邮件。服务器开放的是 25 号端口。
- POP3（邮件读取协议）：它是和 SMTP 对应，POP3 用于接收邮件。POP3 协议所用的是 110 端口。
- HTTP（超文本传输协议）：是从 Web 服务器传输超文本到本地浏览器的传送协议。
- HTTPS（超文本传输安全协议）

### 基于 UDP 协议的

- TFTP（简单文件传输协议）：该协议在熟知端口 69 上使用 UDP 服务。
- SNMP（简单网络管理协议）：使用 161 号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。
- BOOTP（引导程序协议，DHCP 的前身）：应用于无盘设备
- DHCP（动态主机配置协议）：是一个局域网的网络协议
- RIP（路由信息协议）：基于距离矢量算法的路由协议，利用跳数来作为计量标准。
- IGMP（Internet 组管理协议）

### 基于 TCP 和 UDP 协议的

- DNS（域名系统）：DNS 区域传输的时候使用 TCP 协议。域名解析时使用 UDP 协议。DNS 用的是 53 号端口。
- ECHO（回绕协议）

# 网络元素

## URL

URL 是 Uniform Resource Locator 的缩写，用于标识和定位互联网上的资源，如网页、图片、视频等。它通常由若干部分组成，包括协议标识符（如 "http" 或 "https"）、服务器名称或 IP 地址、路径和文件名。URL 的结构可以让用户或程序轻松地访问互联网上的资源。

### URL组成

# 7 常用协议

## HTTP

### 作用

### 组成

# 8 问题

## HTTP（Hypertext Transfer Protocol）和 HTTPS（Hypertext Transfer Protocol Secure）

HTTP和HTTPS是用于在客户端和服务器之间传输数据的两种协议，它们之间的主要区别如下：

1. HTTP 传输的数据都是未加密的，也就是明文的，HTTPS 协议是由 HTTP 和 SSL 协议构建的可进行加密传输和身份认证的网络协议，比 HTTP 协议的安全性更高。
2. HTTPS 协议需要 CA 证书；
3. 使用不同的链接方式，端口也不同，一般而言，HTTP 协议的端口为 80，HTTPS 的端口为 443；

### URL前缀

 HTTP的URL以"http://"开头，而HTTPS的URL以"https://"开头，用于标识使用的协议。

### 端口号

HTTP默认使用端口号80进行通信，而HTTPS默认使用端口号443。

### 安全性

HTTP是明文传输协议，数据在传输过程中不进行加密，因此容易被窃听和篡改。而HTTPS通过使用SSL（Secure Sockets Layer）或TLS（Transport Layer Security）协议对数据进行加密和身份验证，确保传输的数据在网络上是安全的，提供了更高的安全性。

### 连接方式

HTTP是无连接的协议，每个请求都需要建立一个新的连接，服务器处理完请求后立即关闭连接。而HTTPS通过SSL/TLS在客户端和服务器之间建立安全的、持久的连接，可以在多个请求之间保持连接状态，减少了连接的建立和关闭的开销。

### 证书

HTTPS使用数字证书来验证服务器的身份。证书由受信任的第三方机构（如证书颁发机构）签发，用于确认服务器的真实性。客户端在建立HTTPS连接时会验证服务器的证书，确保通信的安全性和可靠性。

综上所述，HTTP和HTTPS的主要区别在于安全性、端口号、证书、连接方式和URL前缀等方面。对于需要保护数据安全和隐私的网站或应用程序，使用HTTPS协议是更为安全和可靠的选择。

## https加密方式

HTTPS使用了以下加密技术来确保通信的安全性：

- ##### SSL（Secure Sockets Layer）/TLS（Transport Layer Security）协议
  
  SSL和TLS是建立在传输层之上的安全协议，用于在客户端和服务器之间建立加密的通信连接。TLS是SSL的继任者，目前广泛应用于HTTPS通信中。它们使用对称加密、非对称加密和散列函数等算法来加密和验证通信数据。

- ##### 对称加密
  
  在HTTPS通信的过程中，对称加密算法用于加密和解密实际的数据传输。对称加密使用相同的密钥对数据进行加密和解密，因此在建立HTTPS连接时，客户端和服务器需要协商并共享相同的密钥。常用的对称加密算法包括AES（Advanced Encryption Standard）和3DES（Triple Data Encryption Standard）。

- ##### 非对称加密
  
  非对称加密算法使用一对密钥，包括公钥和私钥。公钥用于加密数据，私钥用于解密数据。在HTTPS通信中，服务器会生成一对密钥，并将公钥发送给客户端。客户端使用服务器的公钥对数据进行加密，只有服务器拥有相应的私钥才能解密数据。常用的非对称加密算法包括RSA（Rivest-Shamir-Adleman）和ECC（Elliptic Curve Cryptography）。

- ##### 数字证书
  
  数字证书用于验证服务器的身份和建立信任关系。证书由受信任的第三方机构（如证书颁发机构）签发，包含服务器的公钥和相关信息。客户端在建立HTTPS连接时会验证服务器的证书，确保通信的安全性和可靠性。

- ##### 散列函数
  
  散列函数用于生成消息摘要，用于确保数据的完整性和防止篡改。常用的散列函数包括SHA（Secure Hash Algorithm）系列和MD5（Message Digest Algorithm 5）。在HTTPS通信中，散列函数用于计算数据的哈希值，将其与接收到的哈希值进行比对，以验证数据的完整性。

综上所述，HTTPS使用SSL/TLS协议、对称加密、非对称加密、数字证书和散列函数等加密技术来确保通信的机密性、完整性和身份验证。这些技术的组合使得HTTPS成为一种安全可靠的通信协议。

HTTP和HTTPS有什么区别？

1. 端口不同：HTTP使用的是80端口，HTTPS使用443端口；
2. HTTP（超文本传输协议）信息是明文传输，HTTPS运行在SSL(Secure Socket Layer)之上，添加了加密和认证机制，更加安全；
3. HTTPS由于加密解密会带来更大的CPU和内存开销；
4. HTTPS通信需要证书，一般需要向证书颁发机构（CA）购买

## Https的连接过程

1. 客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；
2. 服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，**加密公钥**（用于非对称加密），以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密）；
3. 客户端验证服务器的合法性，包括：证书是否过期，CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配；
4. 如果证书受信任，或者用户接收了不受信任的证书，浏览器会生成一个**随机密钥**（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手消息进行**摘要**计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器；
5. 服务器使用自己的私钥解密，得到对称加密的密钥，用这个密钥解密出Hash摘要值，并验证握手消息是否一致；如果一致，服务器使用对称加密的密钥加密握手消息发给浏览器；
6. 浏览器解密并验证摘要，若一致，则握手结束。之后的数据传送都使用对称加密的密钥进行加密

总结：非对称加密算法用于在握手过程中加密生成的密码；对称加密算法用于对真正传输的数据进行加密；HASH算法用于验证数据的完整性。

## 打开⼀个⽹页,使⽤到了哪些其他协议

要确定打开一个网页时使用了哪些其他协议，我们需要考虑网页的不同组成部分和与之相关的协议。通常，打开一个网页可能涉及以下几个协议：

- ##### HTTP/HTTPS协议
  
  网页的传输通常使用HTTP（超文本传输协议）或其安全版本HTTPS（安全超文本传输协议）。HTTP用于在客户端和服务器之间传输网页内容和数据。

- ##### DNS协议
  
  在打开一个网页之前，需要通过DNS（域名系统）协议将网页的域名解析为相应的IP地址。DNS协议负责将域名转换为可识别的IP地址，以便客户端能够与服务器建立连接。

- ##### TCP/IP协议
  
  TCP（传输控制协议）和IP（Internet协议）是互联网通信的基础协议。打开网页时，客户端和服务器之间的数据传输通常使用TCP/IP协议。

- ##### SSL/TLS协议
  
  如果打开的网页使用了HTTPS协议，那么在HTTP之上会使用SSL（安全套接层）或TLS（传输层安全）协议来进行加密通信，确保数据传输的安全性。

- ##### HTML/CSS/JavaScript
  
  网页的内容通常由HTML（超文本标记语言）、CSS（层叠样式表）和JavaScript组成。这些不是传统意义上的协议，但它们是构建和呈现网页所必需的标准技术。

## HTTP状态码

HTTP状态码是在客户端与服务器之间进行通信时，用于表示请求状态和响应状态的数字代码。以下是常见的HTTP状态码范围及其对应的含义：

- ##### 1xx（信息性状态码）：表示请求已被接收，继续处理。
  
  - 100：继续（Continue）
  - 101：切换协议（Switching Protocols）
  - 102：处理中（Processing）

- ##### 2xx（成功状态码）：表示请求已成功处理和接受。
  
  - 200：成功（OK）
  - 201：已创建（Created）
  - 202：已接受（Accepted）
  - 204：无内容（No Content）
  - 206 Partial Content 请求资源的某一部分

- ##### 3xx（重定向状态码）：表示需要进一步操作以完成请求。
  
  - 301：永久重定向（Moved Permanently）
  - 302：临时重定向（Found / Moved Temporarily）
  - 303 告诉客户端应该用另一个 URL 获取资源
  - 304：未修改（Not Modified）

- ##### 4xx（客户端错误状态码）：表示客户端发送的请求有错误。
  
  - 400：错误的请求（Bad Request）
  - 401：未授权（Unauthorized）
  - 403：禁止访问（Forbidden）
  - 404：未找到（Not Found）

- ##### 5xx（服务器错误状态码）：表示服务器在处理请求时发生错误。
  
  - 500：服务器内部错误（Internal Server Error）
  - 502：错误的网关（Bad Gateway）
  - 503：服务不可用（Service Unavailable）
  - 504：网关超时（Gateway Timeout）

## 三次握手 (three-way handshake)

1、第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 SN(c)。此时客户端处于 SYN*Send 状态。
2、第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 _SYN_REVD* 的状态。
3、第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised 状态。
4、服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。

- 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。

- 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。

- 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

- 如果没有第三次握手，就会出现一些丢包的情况，如果只握手 2 次，第二次握手时如果服务端发给客户端的确认报文段丢失，此时服务端已经准备好了收发数(可以理解服务端已经连接成功)据，而客户端一直没收到服务端的确认报文，所以客户端就不知道服务端是否已经准备好了(可以理解为客户端未连接成功)，这种情况下客户端不会给服务端发数据，也会忽略服务端发过来的数据。如果是三次握手，即便发生丢包也不会有问题，比如如果第三次握手客户端发的确认 ack 报文丢失，服务端在一段时间内没有收到确认 ack 报文的话就会重新进行第二次握手，也就是服务端会重发 SYN 报文段，客户端收到重发的报文段后会再次给服务端发送确认 ack 报文。

### TCP建立连接可以两次握手吗？为什么?

不可以。有两个原因：

首先，可能会出现**已失效的连接请求报文段又传到了服务器端**。

> client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server。本来这是一个早已失效的报文段。但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用 “三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有发出建立连接的请求，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用 “三次握手” 的办法可以防止上述现象发生。例如刚才那种情况，client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。

其次，两次握手无法保证Client正确接收第二次握手的报文（Server无法确认Client是否收到），也无法保证Client和Server之间成功互换初始序列号。

还有就是两次握手会给SYN flood攻击提供机会。
扩展阅读： 什么是SYN攻击？https://zhuanlan.zhihu.com/p/360479307

</details>

### 可以采用四次握手吗？为什么？

可以。但是会降低传输的效率。

四次握手是指：第二次握手：Server只发送ACK和acknowledge number；而Server的SYN和初始序列号在第三次握手时发送；原来协议中的第三次握手变为第四次握手。出于优化目的，四次握手中的二、三可以合并。

</details>

### 第三次握手中，如果客户端的ACK未送达服务器，会怎样？

Server端：  
由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。

Client端，两种情况：  

1. 在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态  

2. 在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。
   
   </details>

### 如果已经建立了连接，但客户端出现了故障怎么办？

服务器每收到一次客户端的请求后都会重新复位一个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

</details>

### 初始序列号

TCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002...三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。

</details>

## 四次挥手

刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则：
1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 FIN_WAIT1 状态。
2、第二次握手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT 状态。
3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。
4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态
5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。

- 为什么客户端发送 ACK 之后不直接关闭，而是要等一阵子才关闭。这其中的原因就是，要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 ACK 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。

- 第一次挥手：Client将FIN置为1，发送一个序列号seq给Server；进入FIN_WAIT_1状态；

- 第二次挥手：Server收到FIN之后，发送一个ACK=1，acknowledge number=收到的序列号+1；进入CLOSE_WAIT状态。此时客户端已经没有要发送的数据了，但仍可以接受服务器发来的数据。

- 第三次挥手：Server将FIN置1，发送一个序列号给Client；进入LAST_ACK状态；

- 第四次挥手：Client收到服务器的FIN后，进入TIME_WAIT状态；接着将ACK置1，发送一个acknowledge number=序列号+1给服务器；服务器收到后，确认acknowledge number后，变为CLOSED状态，不再向客户端发送数据。客户端等待2*MSL（报文段最长寿命）时间后，也进入CLOSED状态。完成四次挥手。

##### 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？

因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。

</details>

##### 如果第二次挥手时服务器的ACK没有送达客户端，会怎样？

客户端没有收到ACK确认，会重新发送FIN请求。

</details>

##### 客户端TIME_WAIT状态的意义是什么？

第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。

MSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

</details>

## TCP如何实现流量控制？

使用滑动窗口协议实现流量控制。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在返回ACK时将接受窗口大小放在TCP报文中的窗口字段告知发送方。发送窗口的大小不能超过接受窗口的大小，只有当发送方发送并收到确认之后，才能将发送窗口右移。

发送窗口的上限为接受窗口和拥塞窗口中的较小值。接受窗口表明了接收方的接收能力，拥塞窗口表明了网络的传送能力。

## 什么是零窗口（接收窗口为0时会怎样）？

如果接收方没有能力接收数据，就会将接收窗口设置为0，这时发送方必须暂停发送数据，但是会启动一个持续计时器(persistence timer)，到期后发送一个大小为1字节的探测数据包，以查看接收窗口状态。如果接收方能够接收数据，就会在返回的报文中更新接收窗口大小，恢复数据传送。

</details>

## TCP的拥塞控制

拥塞控制主要由四个算法组成：**慢启动（Slow Start）、拥塞避免（Congestion voidance）、快重传 （Fast Retransmit）、快恢复（Fast Recovery）**

1. 慢启动：刚开始发送数据时，先把拥塞窗口（congestion window）设置为一个最大报文段MSS的数值，每收到一个新的确认报文之后，就把拥塞窗口加1个MSS。这样每经过一个传输轮次（或者说是每经过一个往返时间RTT），拥塞窗口的大小就会加倍

2. 拥塞避免：当拥塞窗口的大小达到慢开始门限(slow start threshold)时，开始执行拥塞避免算法，拥塞窗口大小不再指数增加，而是线性增加，即每经过一个传输轮次只增加1MSS.  
   
   > 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。**（这是不使用快重传的情况）**

3. 快重传：快重传要求接收方在收到一个失序的报文段后就立即发出**重复确认**（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

4. 快恢复：当发送方连续收到三个重复确认时，就把慢开始门限减半，然后执行拥塞避免算法。不执行慢开始算法的原因：因为如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方认为现在网络可能没有出现拥塞。  
   也有的快重传是把开始时的拥塞窗口cwnd值再增大一点，即等于 ssthresh + 3*MSS 。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中。可见现在网络中减少了三个分组。因此可以适当把拥塞窗口扩大些。

## TCP如何最大利用带宽？

TCP速率受到三个因素影响

- 窗口：即滑动窗口大小，见[TCP如何实现流量控制？](#TCP如何实现流量控制)
- 带宽：这里带宽是指单位时间内从发送端到接收端所能通过的“最高数据率”，是一种硬件限制。TCP发送端和接收端的数据传输数不可能超过两点间的带宽限制。发送端和接收端之间带宽取所通过线路的带宽最小值（如通过互联网连接）。
- RTT：即Round Trip Time，表示从发送端到接收端的一去一回需要的时间，TCP在数据传输过程中会对RTT进行采样（即对发送的数据包及其ACK的时间差进行测量，并根据测量值更新RTT值），TCP根据得到的RTT值更新RTO值，即Retransmission TimeOut，就是重传间隔，发送端对每个发出的数据包进行计时，如果在RTO时间内没有收到所发出的数据包的对应ACK，则任务数据包丢失，将重传数据。一般RTO值都比采样得到的RTT值要大。

<details>
<summary>带宽时延乘积</summary>

带宽时延乘积=带宽*RTT，实际上等于发送端到接收端单向通道的数据容积的两倍，这里单向通道的数据容积可以这样来理解，单向通道看成是一条单行道马路，带宽就是马路的车道数，路上跑的汽车就是数据（不过这里所有汽车的速率都是一样的，且不会有人想超车，大家齐头并进），那么单向通道的数据容积就是这条单行道上摆满车，一共可以摆多少辆。带宽就是马路的车道数，带宽数乘以单向通道的数据容积就是路面上所能容纳的全部数据量。当路面上已经摆满的时候，就不能再往里面放了。

</details>

设滑动窗口大小为， 发送端和接收端的带宽为， RTT为。

前面已经说过了，TCP发送数据时受滑动窗口的限制，当TCP将滑动窗口中的数据都发出后，在收到第一个ACK之前，滑动窗口大小是0，不能再发送数据了，必须等待ACK包使滑动窗口移动。那么在理想情况下，ACK包应该在什么时候到达呢？显然，就是在数据发出后的RTT时间后，ACK包到达。这也就是说，现在在不考虑丢包和拥塞情况下，TCP在一个RTT时间内能发出的最大数据量为  ，所以不考虑带宽限制下，TCP能一个时刻能达到的最大速度是 。

现在再考虑带宽限制，前面说过当马路上摆满车的时候，就无法再往里放车了，同理，TCP发送端在  时间内，能往通道上放的最大数据量为  ，通过带宽时延乘积得到的容积限制为 。当  时，单向通道容积不构成瓶颈，速率的限制主要来源于窗口大小限制。而当  时，则就受到容积限制，即此时速率限制来源于带宽限制。

因此，TCP的最大速率为 

在我们平时生活中使用的宽带网络，ADSL等环境下，因为带宽都比较小，从而  也比较小，再加上网络情况比较复杂，拥塞情况比较常见，所以这些网络环境下，TCP速率的主要限制因素在于带宽，丢包率等。长肥管道一般不太常见，多见于一些单位使用的专线网络，在这些网络中速率的主要限制因素就是窗口大小了，这也是传统TCP在这些网络环境中不能充分利用带宽的原因所在（因为传统TCP的窗口大小是用2字节表示的，所以最大只有65535（不考虑窗口扩大选项）），除了专线网络外，随着网络硬件技术的发展，万兆交换机的出现，局域网中也可能会出现带宽时延乘积较大的情况。

## TCP与UDP

TCP：传输控制协议 

UDP：用户数据报协议

1. TCP 是面向连接的，UDP 是无连接的即发送数据前不需要先建立链接；

2. TCP 提供可靠的服务。也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付。

3. TCP 是面向字节流，UDP 面向报文；

4. TCP 只能是 1 对 1 的，UDP 支持 1 对 1,1 对多；

5. TCP 的首部较大为 20 字节，而 UDP 只有 8 字节；

6. TCP是面向连接的，UDP是无连接的；
   
   什么叫无连接？UDP发送数据之前不需要建立连接

</details>

2. TCP是可靠的，UDP不可靠；
   
   什么叫不可靠？UDP接收方收到报文后，不需要给出任何确认

</details>

3. TCP只支持点对点通信，UDP支持一对一、一对多、多对一、多对多；

4. TCP是面向字节流的，UDP是面向报文的；
   
   什么意思？面向字节流是指发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送，而UDP一个报文只能一次发完。

</details>

5. TCP有拥塞控制机制，UDP没有。网络出现的拥塞不会使源主机的发送速率降低，这对某些实时应用是很重要的，比如媒体通信，游戏；
6. TCP首部开销（20字节）比UDP首部开销（8字节）要大
7. UDP 的主机不需要维持复杂的连接状态表

##### 什么时候选择TCP，什么时候选UDP？

对某些实时性要求比较高的情况，选择UDP，比如游戏，媒体通信，实时视频流（直播），即使出现传输错误也可以容忍；其它大部分情况下，HTTP都是用TCP，因为要求传输的内容可靠，不出现丢失

##### HTTP可以使用UDP吗？

HTTP不可以使用UDP，HTTP需要基于可靠的传输协议，而UDP不可靠

注：**http 3.0 使用udp实现**
https://zh.wikipedia.org/wiki/HTTP/3

</details>

##### 面向连接和无连接的区别

无连接的网络服务（数据报服务）-- 面向连接的网络服务（虚电路服务）

虚电路服务：首先建立连接，所有的数据包经过相同的路径，服务质量有较好的保证；

数据报服务：每个数据包含目的地址，数据路由相互独立（路径可能变化）；网络尽最大努力交付数据，但不保证不丢失、不保证先后顺序、不保证在时限内交付；网络发生拥塞时，可能会将一些分组丢弃；

</details>

### TCP如何保证传输的可靠性

1. 数据包校验
2. 对失序数据包重新排序（TCP报文具有序列号）
3. 丢弃重复数据
4. 应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；
5. 超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；
6. 流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出

</details>

##### 输入 www.baidu.com，怎么变成 https://www.baidu.com 的，怎么确定用HTTP还是HTTPS？

[你访问的网站是如何自动切换到 HTTPS 的？](https://www.sohu.com/a/136637876_487516)

一种是原始的302跳转，服务器把所有的HTTp流量跳转到HTTPS。但这样有一个漏洞，就是中间人可能在第一次访问站点的时候就劫持。
解决方法是引入HSTS机制，用户浏览器在访问站点的时候强制使用HTTPS。

</details>

##### HTTPS连接的时候，怎么确定收到的包是服务器发来的（中间人攻击）？

1.验证域名、有效期等信息是否正确。证书上都有包含这些信息，比较容易完成验证；

2.判断证书来源是否合法。每份签发证书都可以根据验证链查找到对应的根证书，操作系统、浏览器会在本地存储权威机构的根证书，利用本地根证书可以对对应机构签发证书完成来源验证；

3.判断证书是否被篡改。需要与 CA 服务器进行校验；

4.判断证书是否已吊销。通过CRL（Certificate Revocation List 证书注销列表）和 OCSP（Online Certificate Status Protocol 在线证书状态协议）实现，其中 OCSP 可用于第3步中以减少与 CA 服务器的交互，提高验证效率

</details>

##### 什么是对称加密、非对称加密？区别是什么？

- 对称加密：加密和解密采用相同的密钥。如：DES、RC2、RC4

- 非对称加密：需要两个密钥：公钥和私钥。如果用公钥加密，需要用私钥才能解密。如：RSA

- 区别：对称加密速度更快，通常用于大量数据的加密；非对称加密安全性更高（不需要传送私钥）
  
  </details>

##### 数字签名、报文摘要的原理

- 发送者A用私钥进行签名，接收者B用公钥验证签名。因为除A外没有人有私钥，所以B相信签名是来自A。A不可抵赖，B也不能伪造报文。

- 摘要算法:MD5、SHA
  
  </details>

## GET与POST

1. GET是幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的；
2. GET一般用于从服务器获取资源，而POST有可能改变服务器上的资源；
3. 请求形式上：GET请求的数据附在URL之后，在HTTP请求头中；POST请求的数据在请求体中；
4. 安全性：GET请求可被缓存、收藏、保留到历史记录，且其请求数据明文出现在URL中。POST的参数不会被保存，安全性相对较高；
5. GET只允许ASCII字符，POST对数据类型没有要求，也允许二进制数据；
6. GET的长度有限制（操作系统或者浏览器），而POST数据大小无限制

两者本质上都是 TCP 链接

1. get 参数通过 url 传递，post 放在请求体 (request body) 中。
2. get 请求在 url 中传递的参数是有长度限制的（该限制是由浏览器和服务器限制的），而 post 没有。
3. get 请求只能进行 url 编码，而 post 支持多种编码方式。
4. get 请求参数会被完整保留在浏览历史记录里，而 post 中的参数不会被保留。
5. get 产生一个 TCP 数据包；post 产生两个 TCP 数据包。
   对于 get 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；
   而对于 post，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。
6. 

## Session与Cookie

1.存储位置不同：

> cookie 数据存放在客户的浏览器上
> 
> session 数据放在服务器上。

2.存储容量不同：

> 单个 cookie 保存的数据不能超过 4K，一个站点最多保存 20 个 cookie。
> 
> 对于 session 来说并没有上限，但出于对服务器端的性能考虑，session 内不要存放过多的东西，并且设置 session 删除机制。

3.存储方式不同：

> cookie 中只能保管 ASCII 字符串，并需要通过编码方式存储为 Unicode 字符或者二进制数据。
> 
> session 中能够存储任何类型的数据，包括且不限于 string，integer，list，map 等。

4.隐私策略不同

> cookie 对客户端是可见的，别有用心的人可以分析存放在本地的 cookie 并进行 cookie 欺骗，所以它是不安全的。
> 
> session 存储在服务器上，不存在敏感信息泄漏的风险。

5.有效期不同

> cookie 保管在客户端，不占用服务器资源。对于并发用户十分多的网站，cookie 是很好的选择。
> 
> session 是保管在服务器端的，每个用户都会产生一个 session。假如并发访问的用户十分多，会产生十分多的 session，耗费大量的内存。

Session是服务器端保持状态的方案，Cookie是客户端保持状态的方案

Cookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）

## 从输入网址到获得页面的过程

1. 浏览器查询 DNS，获取域名对应的IP地址:具体过程包括浏览器搜索自身的DNS缓存、搜索操作系统的DNS缓存、读取本地的Host文件和向本地DNS服务器进行查询等。对于向本地DNS服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询；
2. 浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手；
3. TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求；
4. 服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器；
5. 浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；
6. 浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。

### 距离矢量路由协议 (Routing Information Protocol，RIP)

每个路由器维护一张表，记录该路由器到其它网络的”跳数“，路由器到与其直接连接的网络的跳数是1，每多经过一个路由器跳数就加1；更新该表时和相邻路由器交换路由信息；路由器允许一个路径最多包含15个路由器，如果跳数为16，则不可达。交付数据报时优先选取距离最短的路径。

（PS：RIP是应用层协议：[https://www.zhihu.com/question/19645407](https://www.zhihu.com/question/19645407)）

优缺点

- 实现简单，开销小

- 随着网络规模扩大开销也会增大；

- 最大距离为15，限制了网络的规模；

- 当网络出现故障时，要经过较长的时间才能将此信息传递到所有路由器

### IP地址的分类

路由器仅根据网络号net-id来转发分组，当分组到达目的网络的路由器之后，再按照主机号host-id将分组交付给主机；同一网络上的所有主机的网络号相同。

### 划分子网

从主机号host-id借用若干个比特作为子网号subnet-id；子网掩码：网络号和子网号都为1，主机号为0；数据报仍然先按照网络号找到目的网络，发送到路由器，路由器再按照网络号和子网号找到目的子网：将子网掩码与目标地址逐比特与操作，若结果为某个子网的网络地址，则送到该子网。

### ARP协议 (Address Resolution Protocol)

**ARP协议完成了IP地址与物理地址的映射**。每一个主机都设有一个 ARP 高速缓存，里面有**所在的局域网**上的各主机和路由器的 IP 地址到硬件地址的映射表。当源主机要发送数据包到目的主机时，会先检查自己的ARP高速缓存中有没有目的主机的MAC地址，如果有，就直接将数据包发到这个MAC地址，如果没有，就向**所在的局域网**发起一个ARP请求的广播包（在发送自己的 ARP 请求时，同时会带上自己的 IP 地址到硬件地址的映射），收到请求的主机检查自己的IP地址和目的主机的IP地址是否一致，如果一致，则先保存源主机的映射到自己的ARP缓存，然后给源主机发送一个ARP响应数据包。源主机收到响应数据包之后，先添加目的主机的IP地址与MAC地址的映射，再进行数据传送。如果源主机一直没有收到响应，表示ARP查询失败。

如果所要找的主机和源主机不在同一个局域网上，那么就要通过 ARP 找到一个位于本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络。剩下的工作就由下一个网络来做。

### NAT (Network Address Translation, 网络地址转换)

用于解决内网中的主机要和因特网上的主机通信。由NAT路由器将主机的本地IP地址转换为全球IP地址，分为静态转换（转换得到的全球IP地址固定不变）和动态NAT转换。

## HTTP各版本

- HTTP 0.9版本
  
  - HTTP协议的第一个版本，功能简单，**已弃用**
  - 仅支持纯文本数据的传输，虽然支持HTML，但是不支持图片插入
  - 仅支持GET请求方式，且不支持请求头
  - 无状态，短连接。没有对用户状态的管理；每次请求建立一个TCP连接，响应之后关闭TCP连接。

- HTTP 1.0版本
  
  - 支持POST、GET、HEAD三种方法
  - **支持长连接keep-alive**（但**默认还是使用短连接**：浏览器每一次请求建立一次TCP连接，请求处理完毕之后断开）。
  - 服务器不跟踪用户的行为也不记录用户过往请求。

- HTTP 1.1版本
  
  - 新增PUT、DELETE、CONNECT、TRACE、OPTIONS方法，是现今**使用最多**的版本。
  - 支持长连接，在一次TCP连接中可以发送多个请求或响应，且默认使用长连接。
  - 支持宽带优化、断点续传。请求的对象部分数据，可以不必发送整个对象；文件上传下载支持续传。
  - 因为长连接产生的问题：队头阻塞。长连接中，发送请求和响应都是串行化的，前面的消息会造成后面的消息也阻塞。解决方法是创建多个TCP连接，这样就可以基本保证了可用性，浏览器**默认的最大TCP连接数是6个**。

- HTTP 2.0版本
  
  - 二进制分帧，所有帧都是用二进制编码，节省了空间
  - 多路复用：HTTP 2.0中所有的连接都是持久化的。相比1.1版本可以不用维护更多的TCP连接，在处理并发请求的时候，可以将多个数据流中**互不依赖的帧**可以**乱序发送**，同时还支持**优先级**。接收方接收之后可以根据帧头部信息将帧组合起来。（解决了1.1版本中的队头阻塞问题）
  - 头部压缩：1.1版本每次传输都需要传输一份首部，2.0让双方各自缓存一份首部字段表，达到更快传输的目标。

- HTTP 3.0版本
  
  - 基于UDP的**QUIC多路复用**：在一个QUIC中可以并发发送多个HTTP请求Stream，且如果各个Stream互不依赖，那么就不会造成**使用TCP带来的队头阻塞问题**。这个问题源头上是因为TCP连接，TCP连接的性质决定了重传会影响队后的数据发送，所以干脆选用UDP来解决这个方案。
  - 0RRT建链：RRT表示Round-Trip Time，3.0可以实现0RRT建链。一般来说HTTPS协议要建立完整链接包括**TCP握手**和**TLS握手**，总计需要至少2-3个RTT，普通的HTTP协议也需要至少1个RTT才可以完成握手。基于UDP的QUIC协议可以在第一次发送包的时候直接发送业务数据。但是由于首次连接需要发送公钥数据，所以首次连接并不使用这一方法。
  
  > 参考文档：[图解 | 为什么HTTP3.0要弃用TCP协议，而改用UDP协议？_涛哥聊Python-CSDN博客](

### HTTP1.0 和 HTTP1.1 和 HTTP2.0 的区别

超文本传输协议（HTTP）用于浏览器与服务器之间的通信

### HTTP1.0 和 HTTP1.1

1. 缓存处理：
- 1.0 的 header 中主要是通过 If-Modified-Since（比较资源的最后的更新时间是否一致），expires(资源的过期时间，取决于客户端本地时间)

- 1.1 引入了其他的 If-Match(比较 ETag 是否一致), If-None-Match(比较 ETag 是否不一致), If-Unmodified-Since(比较资源最后的更新时间是否不一致), Entity tag(资源的匹配信息)
2. 带宽优化
- 1.0 存在一些浪费带宽的现象，例如客户端只需要某个对象的一部分，但是服务器将整个对象返回。

- 1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content）
3. Host 头处理
- 1.0 中认为每个服务器都有一个唯一的 Ip，因此请求的 url 中并没有传递主机名（hostname）

- 随着虚拟化技术的发展，一台物理机上可以有多个虚拟机，共享同一个 ip，1.1 中的请求消息和响应消息都支持 Host，请求消息中如果没有 Host 头域会报告一个错误（400 Bad Request）
4. 长连接
- http 是基于 TCP/IP 协议的，创建一个 TCP 连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接，可以用个长连接来发多个请求。

- 1.0 中每次需要使用 keep-alive 参数来告知服务器端要建立一个长连接

- 1.1 默认支持长连接，一定程度上弥补了 HTTP1.0 每次请求都要创建连接的缺点
5. 新增状态码
- 1.1 中新增了 24 个错误状态响应码，如 409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除
6. 新增请求方式
- PUT，DELETE，OPTIONS 等

### http2.0 与 http1.X 区别

> 参考链接：[HTTP/2 相比 1.0 有哪些重大改进？](https://www.zhihu.com/question/34074946)

1. header 压缩: header 头部带有大量的信息，而且每次使用报头压缩，降低开销，对于相同的 header 数据，不再通过每次请求和响应发送，差量更新 HTTP 头部，既避免了重复 header 的传输，又减小了需要传输的大小
2. 多路复用:在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序
3. 二进制分帧:消息由一个或多个帧组成。多个帧之间可以乱序发送
4. 服务端推送:HTTP2 引入服务器推送，允许服务端推送资源给客户端,服务器会顺便把一些客户端需要的资源一起推送到客户端

## HTTPS 协议的工作原理

1. 客户使用 HTTPS URL 访问服务器，则要求 web 服务器建立 SSL 链接，客户端向服务器发送的报文包括客户端所支持的 ssl 版本，支持的加密算法以及密钥的长度。
2. web 服务器接收到客户端的请求之后，也在报文中包含 SSL 版本以及加密组件，服务器的加密组件内容时从接收到的客户端加密组件内筛选出来的。
3. 同时，web 服务器会将网站的 CA 证书（证书中包含了公钥），返回给客户端。
4. 客户端通过 CA 证书来验证服务端的身份，公钥是否有效，比如颁发机构，过期时间，并随机生成对称加密的密钥 X 用公钥加密发给服务端。
5. 服务器拿到客户端发过来的加密内容用自己的私钥解密获取到密钥 X。
6. 双方都拿到了密钥 X，SSL 通道建立完成，通过密钥 X 加密信息来进行通信。
   总结：HTTPS 协议使用了非对称加密 + 对称加密的方式，即利用了非对称加密安全性高的特点，又利用了对称加密速度快，效率高的好处

## 对称加密和非对称加密的区别

## WebSocket 协议

> 参考链接：[HTML5 WebSocket](https://www.runoob.com/html/html5-websocket.html)

WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。

WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。

现在，很多网站为了实现推送技术，所用的技术都是 Ajax 轮询。轮询是在特定的的时间间隔（如每 1 秒），由浏览器对服务器发出 HTTP 请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而 HTTP 请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。

应用场景:实现即时通讯:如股票交易行情分析、聊天室、在线游戏等，替代轮询和长轮询

## 什么是浏览器的同源政策

```txt
我对浏览器的同源政策的理解是，一个域下的 js 脚本在未经允许的情况下，不能够访问另一个域的内容。这里的同源的指的是两个
域的协议、域名、端口号必须相同，否则则不属于同一个域。

同源政策主要限制了三个方面

第一个是当前域下的 js 脚本不能够访问其他域下的 cookie、localStorage 和 indexDB。

第二个是当前域下的 js 脚本不能够操作访问其他域下的 DOM。

第三个是当前域下 ajax 无法发送跨域请求。

同源政策的目的主要是为了保证用户的信息安全，它只是对 js 脚本的一种限制，并不是对浏览器的限制，对于一般的 img、或者
script 脚本请求都不会有跨域的限制，这是因为这些操作都不会通过响应结果来进行可能出现安全问题的操作。
```

## HTTP 请求的方式

1. GET：请求指定的页面信息，并返回实体主体。
2. HEAD：类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头
3. POST：向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。
4. PUT：从客户端向服务器传送的数据取代指定的文档的内容。
5. DELETE：请求服务器删除指定的页面。
6. CONNECT：HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。
7. OPTIONS：允许客户端查看服务器的性能。
8. TRACE：回显服务器收到的请求，主要用于测试或诊断。

## 浏览器输入 URL 之后发生了什么

> 参考链接：[在浏览器输入 URL 回车之后发生了什么（超详细版）](https://4ark.me/post/b6c7c0a2.html)

1. DNS 解析
2. TCP 连接
3. 发送 HTTP 请求
4. 服务器处理请求并返回 HTTP 报文
5. 浏览器解析渲染页面
6. 连接结束

## DNS 的具体过程

1. 输入 IP，此时电脑发送一个 DNS 请求到本地 DNS 服务器（一般是网络接入服务商提供 eg:电信，移动）
2. 本地 DNS 服务器会首先查询它的缓存记录，若有，则直接返回结果，若没有，本地 DNS 服务器还要向 DNS 根服务器进行查询；
3. DNS 根服务器没有记录具体域名和 IP 地址的对应关系，而是告诉本地 DNS 服务器，可到域服务器上继续查询，并给出域服务器地址
4. 本地服务器继续向域服务器发出请求，返回域名的解析服务器地址
5. 本地 DNS 向域名解析服务器发出请求，收到域名与 IP 地址对应关系
6. 本地 DNS 服务器将 IP 地址返回电脑，且保存副本到缓存已备下次查询

## Cookie 和 WebStorage(SessionStorage 和 LocalStorage)的区别

1. 都会在浏览器端保存，有大小限制，同源限制
2. cookie 会在请求时发送到服务器，作为会话标识，服务器可修改 cookie；web storage 不会发送到服务器
3. cookie 有 path 概念，子路径可以访问父路径 cookie，父路径不能访问子路径 cookie
4. 有效期：cookie 在设置的有效期内有效，默认为浏览器关闭；sessionStorage 在窗口关闭前有效；localStorage 长期有效，直到用户删除
5. 作用域不同 sessionStorage：不在不同的浏览器窗口中共享，即使是同一个页面；localStorage：在所有同源窗口都是共享的；cookie：也是在所有同源窗口中共享的
6. 存储大小不同：cookie 数据不能超过 4K；webStorage 虽然也有存储大小的限制，但是比 cookie 大得多，可以达到 5M 或更大

## 能设置或读取子域的 cookie 吗

> 不行! 只能向当前域或者更高级域设置 cookie
> 
> 例如 client.com 不能向 a.client.com 设置 cookie, 而 a.client.com 可以向 client.com 设置 cookie
> 
> 读取 cookie 情况同上

## 客户端设置 cookie 与服务端设置 cookie 有什么区别

> 无论是客户端还是服务端, 都只能向自己的域或者更高级域设置 cookie，例如 client.com 不能向 server.com 设置 cookie, 同样 server.com 也不能向 client.com 设置 cookie
> 
> 服务端可以设置 `httpOnly: true`, 带有该属性的 cookie 客户端无法读取
> 
> 客户端只会带上与请求同域的 cookie, 例如 client.com/index.html 会带上 client.com 的 cookie，server.com/app.js 会带上 server.com 的 cookie, 并且也会带上 httpOnly 的 cookie

## 同域/跨域 ajax 请求到底会不会带上 cookie

> fetch 在默认情况下, 不管是同域还是跨域 ajax 请求都不会带上 cookie, 只有当设置了 credentials 时才会带上该 ajax 请求所在域的 cookie, 服务端需要设置响应头`Access-Control-Allow-Credentials: true`, 否则浏览器会因为安全限制而报错, 拿不到响应
> 
> axios 和 jQuery 在同域 ajax 请求时会带上 cookie, 跨域请求不会, 跨域请求需要设置 `withCredentials` 和服务端响应头`Access-Control-Allow-Credentials`

- fetch 设置 credentials 使 fetch 带上 cookie
  
  ```js
  fetch(url, {
    credentials: 'include', // include, same-origin, omit
  });
  ```

- axios 设置 withCredentials 使 axios 带上 cookie
  
  ```js
  axios.get('http://server.com', { withCredentials: true });
  ```

- jQuery 设置 withCredentials
  
  ```js
  $.ajax({
    method: 'get',
    url: 'http://server.com',
    xhrFields: {
      withCredentials: true,
    },
  });
  ```

## 前端攻击技术

### XSS 攻击(cross-site script)

1. XSS 攻击形式：
   
   主要是通过 html 标签注入，篡改网页，插入恶意的脚本，前端可能没有经过严格的校验直接就进到数据库，数据库又通过前端程序又回显到浏览器
   
   ```js
   例如一个留言板：
   如果内容是
   hello!<script type="type/javascript src="恶意网址"></script>
   这样会通过前端代码来执行js脚本，如果这个恶意网址通过cookie获得了用户的私密信息，那么用户的信息就被盗了
   ```

2. 攻击的目的：
   
   攻击者可通过这种方式拿到用户的一些信息，例如 cookie 获取敏感信息，甚至自己建网站，做一些非法的操作等；或者，拿到数据后以用户的身份进行勒索，发一下不好的信息等。

3. 攻击防御
   
   方法 1：cookie 中设置 HttpOnly 属性
   
   方法 2：首先前端要对用户输入的信息进行过滤，可以用正则，通过替换标签的方式进行转码或解码，例如<> 空格 & '' ""等替换成 html 编码
   
   ```js
   htmlEncodeByRegExp:function (str){
     var s = "";
     if(str.length == 0) return "";
     s = str.replace(/&/g,"&");
     s = s.replace(/</g,"<");
     s = s.replace(/>/g,">");
     s = s.replace(/ /g," ");
     s = s.replace(/\'/g,"&#39;");
     s = s.replace(/\"/g,""");
     return s;
     }
   ```

### CSRF 攻击(cross site request forgery,跨站请求伪造)

1. CSRF 攻击形式：
   
   CSRF 也是一种网络攻击方式，比起 xss 攻击，是另外一种更具危险性的攻击方式，xss 是站点用户进行攻击，而 csrf 是通过伪装成站点用户进行攻击，而且防范的资源也少，难以防范
   
   csrf 攻击形式：攻击者盗用用户的身份信息，并以用户的名义进行发送恶意的请求等，例如发邮件，盗取账号等非法手段
   
   ```js
   例如：你登录网站，并在本地种下了cookie
   如果在没退出该网站的时候 不小心访问了恶意网站，而且这个网站需要你发一些请求等
   此时，你是携带cookie进行访问的，那么你的种在cookie里的信息就会被恶意网站捕捉到，那么你的信息就被盗用，导致一些不法分子做一些事情
   ```

2. 攻击防御：
- 验证 HTTP Referer 字段
  
  ```js
  在HTTP头中有Referer字段，他记录该HTTP请求的来源地址，如果跳转的网站与来源地址相符，那就是合法的，如果不符则可能是csrf攻击，拒绝该请求
  ```

- 在请求地址中添加 token 并验证
  
  ```js
  这种的话在请求的时候加一个token，值可以是随机产生的一段数字，
  token是存入数据库之后，后台返给客户端的，如果客户端再次登录的时候，
  后台发现token没有，或者通过查询数据库不正确，那么就拒绝该请求
  
  如果想防止一个账号避免在不同的机器上登录，那么我们就可以通过token来判断，
  如果a机器登录后，我们就将用户的token从数据库清除，从新生成，
  那么另外一台b机器在执行操作的时候，token就失效了，只能重新登录，这样就可以防止两台机器登同一账号
  ```

- 在 HTTP 头中自定义属性并验证
  
  ```js
  如果说通过每次请求的时候都得加token那么各个接口都得加很麻烦，
  那么我们通过http的请求头来设置token
  例如：
      $.ajax({
          url: '/v1/api',
          dataType: 'json',
          data: param,
          type:'post',
          headers: {'Accept':'application/json','Authorization':tokenValue}
          success:function(res){
              console.log(res)
          }
      })
  ```

## 浏览器缓存机制

> 参考链接：[HTTP 强缓存和协商缓存](https://segmentfault.com/a/1190000008956069)

浏览器缓存分为：强缓存和协商缓存

在浏览器第一次发起请求时，本地无缓存，向 web 服务器发送请求，服务器起端响应请求，浏览器端缓存。在第一次请求时，服务器会将页面最后修改时间通过 Last-Modified 标识由服务器发送给客户端，客户端记录修改时间；服务器还会生成一个 Etag，并发送给客户端。

根据上图，浏览器在第一次请求发生后，再次发送请求时：

- 浏览器请求某一资源时，会先获取该资源缓存的 header 信息，然后根据 header 中的 Cache-Control 和 Expires 来判断是否过期。若没过期则直接从缓存中获取资源信息，包括缓存的 header 的信息，所以此次请求不会与服务器进行通信。这里判断是否过期，则是强缓存相关。
- 如果显示已过期，浏览器会向服务器端发送请求，这个请求会携带第一次请求返回的有关缓存的 header 字段信息，比如客户端会通过 If-None-Match 头将先前服务器端发送过来的 Etag 发送给服务器，服务会对比这个客户端发过来的 Etag 是否与服务器的相同，若相同，就将 If-None-Match 的值设为 false，返回状态 304，客户端继续使用本地缓存，不解析服务器端发回来的数据，若不相同就将 If-None-Match 的值设为 true，返回状态为 200，客户端重新请求服务器端返回的数据；客户端还会通过 If-Modified-Since 头将先前服务器端发过来的最后修改时间戳发送给服务器，服务器端通过这个时间戳判断客户端的页面是否是最新的，如果不是最新的，则返回最新的内容，如果是最新的，则返回 304，客户端继续使用本地缓存。

## 强缓存 Expires 和 Cache-Control 的使用

强缓存是利用 http 头中的 Expires 和 Cache-Control 两个字段来控制的，用来表示资源的缓存时间。强缓存中，普通刷新会忽略它，但不会清除它，需要强制刷新。浏览器强制刷新，请求会带上`Cache-Control:no-cache` 和 `Pragma:no-cache`

### Expires

Expires 的值是一个绝对时间的 GMT 格式的时间字符串。比如 Expires 值是：`expires:Fri, 14 Apr 2017 10:47:02 GMT`。这个时间代表这这个资源的失效时间，只要发送请求时间是在 Expires 之前，那么本地缓存始终有效，则在缓存中读取数据。

缺点：
由于失效的时间是一个绝对时间，所以当服务器与客户端时间偏差较大时，误差很大，就会导致缓存混乱。

#### Cache-Control

Cache-Control 主要是利用该字段的 `max-age` 值来进行判断，它是一个相对时间，例如`Cache-Control:max-age=3600`，代表着资源的有效期是 3600 秒。

cache-control 除了该字段外，还有下面几个比较常用的设置值：

- no-cache：不使用本地缓存。需要使用缓存协商，先与服务器确认返回的响应是否被更改，如果之前的响应中存在 ETag，那么请求的时候会与服务端验证，如果资源未被更改，则可以避免重新下载。
- no-store：直接禁止浏览器缓存数据，每次用户请求该资源，都会向服务器发送一个请求，每次都会下载完整的资源。
- public：可以被所有的用户缓存，包括终端用户和 CDN 等中间代理服务器。
- private：只能被终端用户的浏览器缓存，不允许 CDN 等中继缓存服务器对其缓存。

Cache-Control 与 Expires 可以在服务端配置同时启用，同时启用的时候 Cache-Control 优先级高。如：

```txt
cache-control:max-age=691200
expires:Fri, 15 May 2020 10:47:02 GMT
```

那么表示资源可以被缓存的最长时间为 691200 秒。

## 协商缓存

协商缓存就是由服务器来确定缓存资源是否可用，所以客户端与服务器端要通过某种标识来进行通信，从而让服务器判断请求资源是否可以缓存访问。

### Etag 和 If-None-Match

`Etag/If-None-Match`返回的是一个校验码。`Etag`可以保证每一个资源是唯一的，资源变化都会导致`Etag`变化。服务器根据浏览器发送的`If-None-Match`值来判断是否命中缓存。

与`Last-Modified`不一样的是，当服务器返回 304 (Not Modified) 的响应时，由于`Etag`重新生成过，response header 中还会把这个`Etag`返回，即使这个`Etag`跟之前的没有变化。

### Last-Modify / If-Modify-Since

浏览器第一次请求一个资源的时候，服务器返回的 header 中会加上 Last-Modify，Last-Modify 是一个时间标识该资源的最后修改时间，例如 Last-Modify: Thu,31 Dec 2037 23:59:59 GMT。当浏览器再次请求该资源时，request 的请求头中会包含 If-Modify-Since，该值为缓存之前返回 Last-Modify。服务器收到 If-Modify-Since 后，根据资源的最后修改时间判断是否命中缓存。如果命中缓存，则返回 304，并且不会返回资源内容，并且不会返回 Last-Modify。

### 为什么要有 Etag

> 两个都可以确定缓存资源的是否可用，有什么区别呢？

`Etag` 的出现主要是为了解决几个 `Last-Modified` 比较难解决的问题：

1. 一些文件也许会周期性的更改，但是他的内容并不改变(仅仅改变的修改时间)，这个时候我们并不希望客户端认为这个文件被修改了，而重新 GET；
2. 某些文件修改非常频繁，比如在秒以下的时间内进行修改，(比方说 1s 内修改了 N 次)，`If-Modified-Since` 能检查到的力度是秒级的，这种修改无法判断；
3. 某些服务器不能精确的得到文件的最后修改时间。

`Last-Modified` 与 `ETag` 是可以一起使用的，服务器会优先验证`ETag`，一致的情况下，才会继续比对 `Last-Modified`，最后才决定是否返回 304。